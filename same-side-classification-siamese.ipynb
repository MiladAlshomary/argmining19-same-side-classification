{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "def get_train_test_sets(df):\n",
    "    X = df[['argument1', 'argument2', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Clasiification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_traindev_df = pd.read_csv(data_cross_path.format('training'), \n",
    "                                quotechar='\"',quoting=csv.QUOTE_ALL,encoding='utf-8',escapechar='\\\\',doublequote=False,  index_col='id')\n",
    "cross_test_df =  pd.read_csv(data_cross_path.format('test'), encoding='utf-8',index_col='id')\n",
    "\n",
    "\n",
    "within_traindev_df =  pd.read_csv(data_within_path.format('training'), \n",
    "                                quotechar='\"',quoting=csv.QUOTE_ALL,encoding='utf-8',escapechar='\\\\',doublequote=False, index_col='id')\n",
    "\n",
    "within_test_df =  pd.read_csv(data_within_path.format('test'), encoding='utf-8',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if title.find('abortion') > -1 :\n",
    "        row['tag'] = 'abortion'\n",
    "    elif title.find('gay marriage') > -1 :\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "within_test_df = within_test_df.apply(add_tag, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within train df: 63903\n",
      "cross train df: 61048\n"
     ]
    }
   ],
   "source": [
    "print('within train df:', len(within_traindev_df))\n",
    "print('cross train df:', len(cross_traindev_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within test df: 31475\n",
      "cross test df: 6163\n"
     ]
    }
   ],
   "source": [
    "print('within test df:', len(within_test_df))\n",
    "print('cross test df:', len(cross_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>i will give my opponent a chance to respond.</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>in this debate, there are a few factors that m...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first i want to thank my opponent for letting ...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>this is my first debate so please just bare wi...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will give my opponent a chance to respond.</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00002-000</td>\n",
       "      <td>in this debate, there are a few factors that m...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00002-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>first i want to thank my opponent for letting ...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>this is my first debate so please just bare wi...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>first i want to thank my opponent for letting ...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>i will give my opponent a chance to respond.</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>first i want to thank my opponent for letting ...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>in this debate, there are a few factors that m...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i will give my opponent a chance to respond.</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00002-000</td>\n",
       "      <td>this is my first debate so please just bare wi...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00002-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in this debate, there are a few factors that m...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00003-000</td>\n",
       "      <td>this is my first debate so please just bare wi...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00003-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abortion is almost always bad for individual w...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>i began this discussion with the premise that ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abortion is almost always bad for individual w...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>dalzuga, you make some good points. it seems l...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i began this discussion with the premise that ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00000-000</td>\n",
       "      <td>dalzuga, you make some good points. it seems l...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00000-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"unfortunately, for many women, it's just not ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00001-000</td>\n",
       "      <td>hi loudounconservative. not having an abortion...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00001-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abortion is almost always bad for individual w...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>\"unfortunately, for many women, it's just not ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abortion is almost always bad for individual w...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>hi loudounconservative. not having an abortion...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00004-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i began this discussion with the premise that ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00000-000</td>\n",
       "      <td>\"unfortunately, for many women, it's just not ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00000-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i began this discussion with the premise that ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00000-000</td>\n",
       "      <td>hi loudounconservative. not having an abortion...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00000-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"unfortunately, for many women, it's just not ...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00001-000</td>\n",
       "      <td>dalzuga, you make some good points. it seems l...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00001-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dalzuga, you make some good points. it seems l...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00002-000</td>\n",
       "      <td>hi loudounconservative. not having an abortion...</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z-00002-000</td>\n",
       "      <td>108eb814-2019-04-18T19:59:31Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion is bad for women.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument1  \\\n",
       "id                                                      \n",
       "0   there are two reasons why this debate should g...   \n",
       "1   there are two reasons why this debate should g...   \n",
       "2   first i want to thank my opponent for letting ...   \n",
       "3        i will give my opponent a chance to respond.   \n",
       "4   there are two reasons why this debate should g...   \n",
       "5   there are two reasons why this debate should g...   \n",
       "6   first i want to thank my opponent for letting ...   \n",
       "7   first i want to thank my opponent for letting ...   \n",
       "8        i will give my opponent a chance to respond.   \n",
       "9   in this debate, there are a few factors that m...   \n",
       "10  abortion is almost always bad for individual w...   \n",
       "11  abortion is almost always bad for individual w...   \n",
       "12  i began this discussion with the premise that ...   \n",
       "13  \"unfortunately, for many women, it's just not ...   \n",
       "14  abortion is almost always bad for individual w...   \n",
       "15  abortion is almost always bad for individual w...   \n",
       "16  i began this discussion with the premise that ...   \n",
       "17  i began this discussion with the premise that ...   \n",
       "18  \"unfortunately, for many women, it's just not ...   \n",
       "19  dalzuga, you make some good points. it seems l...   \n",
       "\n",
       "                               argument1_id  \\\n",
       "id                                            \n",
       "0   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "1   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "2   100c174f-2019-04-18T17:33:51Z-00001-000   \n",
       "3   100c174f-2019-04-18T17:33:51Z-00002-000   \n",
       "4   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "5   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "6   100c174f-2019-04-18T17:33:51Z-00001-000   \n",
       "7   100c174f-2019-04-18T17:33:51Z-00001-000   \n",
       "8   100c174f-2019-04-18T17:33:51Z-00002-000   \n",
       "9   100c174f-2019-04-18T17:33:51Z-00003-000   \n",
       "10  108eb814-2019-04-18T19:59:31Z-00004-000   \n",
       "11  108eb814-2019-04-18T19:59:31Z-00004-000   \n",
       "12  108eb814-2019-04-18T19:59:31Z-00000-000   \n",
       "13  108eb814-2019-04-18T19:59:31Z-00001-000   \n",
       "14  108eb814-2019-04-18T19:59:31Z-00004-000   \n",
       "15  108eb814-2019-04-18T19:59:31Z-00004-000   \n",
       "16  108eb814-2019-04-18T19:59:31Z-00000-000   \n",
       "17  108eb814-2019-04-18T19:59:31Z-00000-000   \n",
       "18  108eb814-2019-04-18T19:59:31Z-00001-000   \n",
       "19  108eb814-2019-04-18T19:59:31Z-00002-000   \n",
       "\n",
       "                                            argument2  \\\n",
       "id                                                      \n",
       "0        i will give my opponent a chance to respond.   \n",
       "1   in this debate, there are a few factors that m...   \n",
       "2   this is my first debate so please just bare wi...   \n",
       "3   in this debate, there are a few factors that m...   \n",
       "4   first i want to thank my opponent for letting ...   \n",
       "5   this is my first debate so please just bare wi...   \n",
       "6        i will give my opponent a chance to respond.   \n",
       "7   in this debate, there are a few factors that m...   \n",
       "8   this is my first debate so please just bare wi...   \n",
       "9   this is my first debate so please just bare wi...   \n",
       "10  i began this discussion with the premise that ...   \n",
       "11  dalzuga, you make some good points. it seems l...   \n",
       "12  dalzuga, you make some good points. it seems l...   \n",
       "13  hi loudounconservative. not having an abortion...   \n",
       "14  \"unfortunately, for many women, it's just not ...   \n",
       "15  hi loudounconservative. not having an abortion...   \n",
       "16  \"unfortunately, for many women, it's just not ...   \n",
       "17  hi loudounconservative. not having an abortion...   \n",
       "18  dalzuga, you make some good points. it seems l...   \n",
       "19  hi loudounconservative. not having an abortion...   \n",
       "\n",
       "                               argument2_id                      debate_id  \\\n",
       "id                                                                           \n",
       "0   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "1   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "2   100c174f-2019-04-18T17:33:51Z-00001-000  100c174f-2019-04-18T17:33:51Z   \n",
       "3   100c174f-2019-04-18T17:33:51Z-00002-000  100c174f-2019-04-18T17:33:51Z   \n",
       "4   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "5   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "6   100c174f-2019-04-18T17:33:51Z-00001-000  100c174f-2019-04-18T17:33:51Z   \n",
       "7   100c174f-2019-04-18T17:33:51Z-00001-000  100c174f-2019-04-18T17:33:51Z   \n",
       "8   100c174f-2019-04-18T17:33:51Z-00002-000  100c174f-2019-04-18T17:33:51Z   \n",
       "9   100c174f-2019-04-18T17:33:51Z-00003-000  100c174f-2019-04-18T17:33:51Z   \n",
       "10  108eb814-2019-04-18T19:59:31Z-00004-000  108eb814-2019-04-18T19:59:31Z   \n",
       "11  108eb814-2019-04-18T19:59:31Z-00004-000  108eb814-2019-04-18T19:59:31Z   \n",
       "12  108eb814-2019-04-18T19:59:31Z-00000-000  108eb814-2019-04-18T19:59:31Z   \n",
       "13  108eb814-2019-04-18T19:59:31Z-00001-000  108eb814-2019-04-18T19:59:31Z   \n",
       "14  108eb814-2019-04-18T19:59:31Z-00004-000  108eb814-2019-04-18T19:59:31Z   \n",
       "15  108eb814-2019-04-18T19:59:31Z-00004-000  108eb814-2019-04-18T19:59:31Z   \n",
       "16  108eb814-2019-04-18T19:59:31Z-00000-000  108eb814-2019-04-18T19:59:31Z   \n",
       "17  108eb814-2019-04-18T19:59:31Z-00000-000  108eb814-2019-04-18T19:59:31Z   \n",
       "18  108eb814-2019-04-18T19:59:31Z-00001-000  108eb814-2019-04-18T19:59:31Z   \n",
       "19  108eb814-2019-04-18T19:59:31Z-00002-000  108eb814-2019-04-18T19:59:31Z   \n",
       "\n",
       "    is_same_side                                       topic       tag  \n",
       "id                                                                      \n",
       "0           True  abortion should be illegal with exceptions  abortion  \n",
       "1           True  abortion should be illegal with exceptions  abortion  \n",
       "2           True  abortion should be illegal with exceptions  abortion  \n",
       "3           True  abortion should be illegal with exceptions  abortion  \n",
       "4          False  abortion should be illegal with exceptions  abortion  \n",
       "5          False  abortion should be illegal with exceptions  abortion  \n",
       "6          False  abortion should be illegal with exceptions  abortion  \n",
       "7          False  abortion should be illegal with exceptions  abortion  \n",
       "8          False  abortion should be illegal with exceptions  abortion  \n",
       "9          False  abortion should be illegal with exceptions  abortion  \n",
       "10          True                  abortion is bad for women.  abortion  \n",
       "11          True                  abortion is bad for women.  abortion  \n",
       "12          True                  abortion is bad for women.  abortion  \n",
       "13          True                  abortion is bad for women.  abortion  \n",
       "14         False                  abortion is bad for women.  abortion  \n",
       "15         False                  abortion is bad for women.  abortion  \n",
       "16         False                  abortion is bad for women.  abortion  \n",
       "17         False                  abortion is bad for women.  abortion  \n",
       "18         False                  abortion is bad for women.  abortion  \n",
       "19         False                  abortion is bad for women.  abortion  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_traindev_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>gay marriage devalues marriage, frequency of o...</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>being unaccustomed to gay marriage is no argument</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>gay marriage, debate on same sex marriage</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>accepted. pro may extend their arguments to th...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>i\"m pro-life. just think about it, your murder...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion (pro life)</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>ultrasounds fit well with pro-choice concepts.</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z-00031-000</td>\n",
       "      <td>ultrasounds are a procedure any pregnant woman...</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z-00031-000</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z</td>\n",
       "      <td>True</td>\n",
       "      <td>mandatory ultrasounds before abortions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29855</th>\n",
       "      <td>abortion should be banned nationally unless it...</td>\n",
       "      <td>a89a42-2019-04-18T19:55:57Z-00003-000</td>\n",
       "      <td>abortion should be banned nationally unless it...</td>\n",
       "      <td>a89a42-2019-04-18T19:55:57Z-00003-000</td>\n",
       "      <td>a89a42-2019-04-18T19:55:57Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be banned nationally unless it...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84168</th>\n",
       "      <td>marriage is defined as between a man and woman</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00092-000</td>\n",
       "      <td>marriage is celebrated because of the assumpti...</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00092-000</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>gay marriage, debate on same sex marriage</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "85249  gay marriage devalues marriage, frequency of o...   \n",
       "2607   accepted. pro may extend their arguments to th...   \n",
       "14632     ultrasounds fit well with pro-choice concepts.   \n",
       "29855  abortion should be banned nationally unless it...   \n",
       "84168     marriage is defined as between a man and woman   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000   \n",
       "14632  475596d3-2019-04-17T11:47:21Z-00031-000   \n",
       "29855    a89a42-2019-04-18T19:55:57Z-00003-000   \n",
       "84168  d2f4b1cd-2019-04-17T11:47:27Z-00092-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "85249  being unaccustomed to gay marriage is no argument   \n",
       "2607   i\"m pro-life. just think about it, your murder...   \n",
       "14632  ultrasounds are a procedure any pregnant woman...   \n",
       "29855  abortion should be banned nationally unless it...   \n",
       "84168  marriage is celebrated because of the assumpti...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000  d2f4b1cd-2019-04-17T11:47:27Z   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000  2a0d32eb-2019-04-18T11:46:44Z   \n",
       "14632  475596d3-2019-04-17T11:47:21Z-00031-000  475596d3-2019-04-17T11:47:21Z   \n",
       "29855    a89a42-2019-04-18T19:55:57Z-00003-000    a89a42-2019-04-18T19:55:57Z   \n",
       "84168  d2f4b1cd-2019-04-17T11:47:27Z-00092-000  d2f4b1cd-2019-04-17T11:47:27Z   \n",
       "\n",
       "       is_same_side                                              topic  \\\n",
       "id                                                                       \n",
       "85249         False          gay marriage, debate on same sex marriage   \n",
       "2607          False                                abortion (pro life)   \n",
       "14632          True             mandatory ultrasounds before abortions   \n",
       "29855         False  abortion should be banned nationally unless it...   \n",
       "84168         False          gay marriage, debate on same sex marriage   \n",
       "\n",
       "                tag  \n",
       "id                   \n",
       "85249  gay marriage  \n",
       "2607       abortion  \n",
       "14632      abortion  \n",
       "29855      abortion  \n",
       "84168  gay marriage  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_traindev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within train df: 63903\n",
      "cross train df: 61048\n"
     ]
    }
   ],
   "source": [
    "print('within train df:', len(within_traindev_df))\n",
    "print('cross train df:', len(cross_traindev_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_cross_df = cross_traindev_df.drop_duplicates(['argument1'])\n",
    "mini_within_df = within_traindev_df.drop_duplicates(['argument1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within train df: 10508\n",
      "cross train df: 7828\n"
     ]
    }
   ],
   "source": [
    "print('within train df:', len(mini_within_df))\n",
    "print('cross train df:', len(mini_cross_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_same_side</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>29792</td>\n",
       "      <td>29792</td>\n",
       "      <td>29792</td>\n",
       "      <td>29792</td>\n",
       "      <td>29792</td>\n",
       "      <td>29792</td>\n",
       "      <td>29792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>34111</td>\n",
       "      <td>34111</td>\n",
       "      <td>34111</td>\n",
       "      <td>34111</td>\n",
       "      <td>34111</td>\n",
       "      <td>34111</td>\n",
       "      <td>34111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              argument1  argument1_id  argument2  argument2_id  debate_id  \\\n",
       "is_same_side                                                                \n",
       "False             29792         29792      29792         29792      29792   \n",
       "True              34111         34111      34111         34111      34111   \n",
       "\n",
       "              topic    tag  \n",
       "is_same_side                \n",
       "False         29792  29792  \n",
       "True          34111  34111  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_traindev_df.groupby('is_same_side').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_same_side</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>29853</td>\n",
       "      <td>29853</td>\n",
       "      <td>29853</td>\n",
       "      <td>29853</td>\n",
       "      <td>29853</td>\n",
       "      <td>29853</td>\n",
       "      <td>29853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>31195</td>\n",
       "      <td>31195</td>\n",
       "      <td>31195</td>\n",
       "      <td>31195</td>\n",
       "      <td>31195</td>\n",
       "      <td>31195</td>\n",
       "      <td>31195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              argument1  argument1_id  argument2  argument2_id  debate_id  \\\n",
       "is_same_side                                                                \n",
       "False             29853         29853      29853         29853      29853   \n",
       "True              31195         31195      31195         31195      31195   \n",
       "\n",
       "              topic    tag  \n",
       "is_same_side                \n",
       "False         29853  29853  \n",
       "True          31195  31195  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_traindev_df.groupby('is_same_side').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from siamese import *\n",
    "import pickle\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df  = cross_traindev_df #cross_traindev_df.sample(1000)\n",
    "within_df = within_traindev_df #within_traindev_df.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding training examples using Flair:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The training ds\n",
    "X_train, y_train = cross_df[['argument1', 'argument2']], cross_df[['is_same_side']]\n",
    "\n",
    "#The dev set should be from different topic\n",
    "cross_test_df  = within_traindev_df[within_traindev_df.tag == 'gay marriage']\n",
    "test_sample_df = cross_test_df.sample(1000)\n",
    "X_dev, y_dev   = test_sample_df[['argument1', 'argument2']], test_sample_df[['is_same_side']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 61048 dev: 1000\n"
     ]
    }
   ],
   "source": [
    "print('train:', len(X_train), 'dev:', len(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1_train, x2_train, y_train = process_df(X_train, y_train, passing_y=True)\n",
    "pickle.dump(x1_train, open('/workspace/ceph_data/same-stance-detection/x1_train_cross_topic.pickle', 'wb'))\n",
    "pickle.dump(x2_train, open('/workspace/ceph_data/same-stance-detection/x2_train_cross_topic.pickle', 'wb'))\n",
    "pickle.dump(y_train, open('/workspace/ceph_data/same-stance-detection/y_train_cross_topic.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_dev, x2_dev, y_dev = process_df(test_sample_df, test_sample_df, passing_y=True)\n",
    "pickle.dump(x1_dev, open('/workspace/ceph_data/same-stance-detection/x1_dev_cross_topic.pickle', 'wb'))\n",
    "pickle.dump(x2_dev, open('/workspace/ceph_data/same-stance-detection/x2_dev_cross_topic.pickle', 'wb'))\n",
    "pickle.dump(y_dev,  open('/workspace/ceph_data/same-stance-detection/y_dev_cross_topic.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_within_train, X_within_dev, y_within_train, y_within_dev = get_train_test_sets(within_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 44732 dev: 19171\n"
     ]
    }
   ],
   "source": [
    "print('train:', len(X_within_train), 'dev:', len(X_within_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_within_train, x2_within_train, y_within_train = process_df(X_within_train, y_within_train, passing_y=True)\n",
    "\n",
    "pickle.dump(x1_within_train, open('/workspace/ceph_data/same-stance-detection/x1_train_within_topic.pickle', 'wb'))\n",
    "pickle.dump(x2_within_train, open('/workspace/ceph_data/same-stance-detection/x2_train_within_topic.pickle', 'wb'))\n",
    "pickle.dump(y_within_train, open('/workspace/ceph_data/same-stance-detection/y_train_within_topic.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_within_dev, x2_within_dev, y_within_dev = process_df(X_within_dev, y_within_dev, passing_y=True)\n",
    "\n",
    "pickle.dump(x1_within_dev, open('/workspace/ceph_data/same-stance-detection/x1_dev_within_topic.pickle', 'wb'))\n",
    "pickle.dump(x2_within_dev, open('/workspace/ceph_data/same-stance-detection/x2_dev_within_topic.pickle', 'wb'))\n",
    "pickle.dump(y_within_dev, open('/workspace/ceph_data/same-stance-detection/y_dev_within_topic.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the embedded data:\n",
    "x1_train_cross_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x1_train_cross_topic.pickle', 'rb'))\n",
    "x2_train_cross_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x2_train_cross_topic.pickle', 'rb'))\n",
    "y_train_cross_topic  = pickle.load(open('/workspace/ceph_data/same-stance-detection/y_train_cross_topic.pickle', 'rb'))\n",
    "\n",
    "x1_dev_cross_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x1_dev_cross_topic.pickle', 'rb'))\n",
    "x2_dev_cross_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x2_dev_cross_topic.pickle', 'rb'))\n",
    "y_dev_cross_topic  = pickle.load(open('/workspace/ceph_data/same-stance-detection/y_dev_cross_topic.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 training data.\n",
      "Loaded 100 development data.\n",
      "Epoch [1/10], Iter [63/62] Train Loss: 0.6929, Val Loss: 0.6907\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [2/10], Iter [63/62] Train Loss: 0.6927, Val Loss: 0.6864\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [3/10], Iter [63/62] Train Loss: 0.6928, Val Loss: 0.6886\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [4/10], Iter [63/62] Train Loss: 0.6927, Val Loss: 0.6871\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [5/10], Iter [63/62] Train Loss: 0.6928, Val Loss: 0.6850\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [6/10], Iter [63/62] Train Loss: 0.6927, Val Loss: 0.6908\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [7/10], Iter [63/62] Train Loss: 0.6926, Val Loss: 0.6890\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [8/10], Iter [63/62] Train Loss: 0.6928, Val Loss: 0.6868\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [9/10], Iter [63/62] Train Loss: 0.6924, Val Loss: 0.6907\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Epoch [10/10], Iter [63/62] Train Loss: 0.6924, Val Loss: 0.6889\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n",
      "Finished training....\n",
      "Accuracy of the model on the 1000.0 training images: 51.4 %%\n",
      "Accuracy of the model on the 100.0 development images: 58.0 %%\n"
     ]
    }
   ],
   "source": [
    "model, training_losses, val_losses = train(10, 4096, 0.000005, \n",
    "                                           x1_train_cross_topic, x2_train_cross_topic, y_train_cross_topic,\n",
    "                                           x1_dev_cross_topic, x2_dev_cross_topic, y_dev_cross_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/workspace/ceph_data/same-stance-detection/cross_topic_model_weights_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within-topic experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the embedded data:\n",
    "x1_train_within_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x1_train_within_topic.pickle', 'rb'))\n",
    "x2_train_within_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x2_train_within_topic.pickle', 'rb'))\n",
    "y_train_within_topic  = pickle.load(open('/workspace/ceph_data/same-stance-detection/y_train_within_topic.pickle', 'rb'))\n",
    "\n",
    "x1_dev_within_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x1_dev_within_topic.pickle', 'rb'))\n",
    "x2_dev_within_topic = pickle.load(open('/workspace/ceph_data/same-stance-detection/x2_dev_within_topic.pickle', 'rb'))\n",
    "y_dev_within_topic  = pickle.load(open('/workspace/ceph_data/same-stance-detection/y_dev_within_topic.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 700 training data.\n",
      "Loaded 300 development data.\n",
      "Epoch [1/10], Iter [44/43] Train Loss: 0.6932, Val Loss: 0.6955\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [2/10], Iter [44/43] Train Loss: 0.6932, Val Loss: 0.6952\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [3/10], Iter [44/43] Train Loss: 0.6931, Val Loss: 0.6953\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [4/10], Iter [44/43] Train Loss: 0.6930, Val Loss: 0.6956\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [5/10], Iter [44/43] Train Loss: 0.6930, Val Loss: 0.6954\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [6/10], Iter [44/43] Train Loss: 0.6929, Val Loss: 0.6955\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [7/10], Iter [44/43] Train Loss: 0.6930, Val Loss: 0.6954\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [8/10], Iter [44/43] Train Loss: 0.6929, Val Loss: 0.6953\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [9/10], Iter [44/43] Train Loss: 0.6928, Val Loss: 0.6954\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Epoch [10/10], Iter [44/43] Train Loss: 0.6929, Val Loss: 0.6954\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n",
      "Finished training....\n",
      "Accuracy of the model on the 700.0 training images: 50.57142857142857 %%\n",
      "Accuracy of the model on the 300.0 development images: 45.0 %%\n"
     ]
    }
   ],
   "source": [
    "model, training_losses, val_losses = train(10, 4096, 0.000005, \n",
    "                                           x1_train_within_topic, x2_train_within_topic, y_train_within_topic,\n",
    "                                           x1_dev_within_topic, x2_dev_within_topic, y_dev_within_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/workspace/ceph_data/same-stance-detection/within_topic_model_weights_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing cross-topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_dev = pickle.load(open('/workspace/webis20_data/same-stance-detection/x1_dev_new.pickle', 'rb'))\n",
    "x2_dev = pickle.load(open('/workspace/webis20_data/same-stance-detection/x2_dev_new.pickle', 'rb'))\n",
    "y_dev  = pickle.load(open('/workspace/webis20_data/same-stance-detection/y_dev_new.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_test_df = within_traindev_df[within_traindev_df.tag == 'gay marriage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loaded 1000 test data.\n",
    "Accuracy of the model on the 1000.0 testing images: 50.8 %%\n",
    "Loaded 1000 test data.\n",
    "Accuracy of the model on the 1000.0 testing images: 53.9 %%\n",
    "Loaded 1000 test data.\n",
    "Accuracy of the model on the 1000.0 testing images: 51.4 %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 2):\n",
    "    test_sample_df = cross_test_df.sample(1000)\n",
    "    x1_test, x2_test, y_test = process_df(test_sample_df, test_sample_df, passing_y=True)\n",
    "    preds = test('/workspace/webis20_data/same-stance-detection/cross_topic_model_weights_new',x1_test, x2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 7.93 GiB total capacity; 6.97 GiB already allocated; 12.56 MiB free; 436.20 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ed31f5563927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_test_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'argument1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argument2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#X_cross = X_cross.sample(20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cross\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassing_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/argmining19-same-side-classification/siamese.py\u001b[0m in \u001b[0;36mprocess_df\u001b[0;34m(xdf, ydf, passing_y)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0msents\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mx1_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   2562\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   1815\u001b[0m             \u001b[0;31m# get hidden states from language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m             all_hidden_states_in_lm = self.lm.get_representation(\n\u001b[0;32m-> 1817\u001b[0;31m                 \u001b[0mtext_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_per_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1818\u001b[0m             )\n\u001b[1;32m   1819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[0;34m(self, strings, start_marker, end_marker, chars_per_chunk)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0moutput_parts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, ordered_sequence_lengths)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 7.93 GiB total capacity; 6.97 GiB already allocated; 12.56 MiB free; 436.20 MiB cached)"
     ]
    }
   ],
   "source": [
    "X_cross = cross_test_df[['argument1', 'argument2']]\n",
    "#X_cross = X_cross.sample(20)\n",
    "x1_test, x2_test, y_test = process_df(X_cross, passing_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_preds = test('/workspace/webis20_data/same-stance-detection/cross_topic_model_weights', x1_test, x2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions ...\n",
    "out_file = open('/workspace/webis20_data/same-stance-detection/cross_topic_test_preds_new.csv', 'w')\n",
    "out_file.write('id,label\\n')\n",
    "for i in range(len(y_preds)):\n",
    "    out_file.write('{},{} \\n'.format(cross_test_df.index[i], 'True' if y_preds[i] == 1.0 else 'False'))\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing within-topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_wtihin_dev = pickle.load(open('/workspace/webis20_data/same-stance-detection/x1_within_dev.pickle', 'rb'))\n",
    "x2_within_dev = pickle.load(open('/workspace/webis20_data/same-stance-detection/x2_within_dev.pickle', 'rb'))\n",
    "y_within_dev  = pickle.load(open('/workspace/webis20_data/same-stance-detection/y_within_dev.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19171 test data.\n",
      "Accuracy of the model on the 19171.0 testing images: 82.37441969641647 %%\n"
     ]
    }
   ],
   "source": [
    "preds = test('/workspace/webis20_data/same-stance-detection/within_topic_model_weights', x1_wtihin_dev, x2_within_dev, y_within_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_within = within_test_df[['argument1', 'argument2']]\n",
    "X_within = X_within.sample(20)\n",
    "x1_within_test, x2_within_test, y_within_test = process_df(X_within, passing_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 test data.\n",
      "Accuracy of the model on the 20.0 testing images: 60.0 %%\n"
     ]
    }
   ],
   "source": [
    "y_preds = test('/workspace/webis20_data/same-stance-detection/within_topic_model_weights', x1_within_test, x2_within_test, y_within_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions ...\n",
    "out_file = open('/workspace/webis20_data/same-stance-detection/within_topic_test_preds_30k.csv', 'w')\n",
    "out_file.write('id,label\\n')\n",
    "for i in range(len(y_preds)):\n",
    "    out_file.write('{},{} \\n'.format(within_test_df.index[i], 'True' if y_preds[i] == 1.0 else 'False'))\n",
    "    \n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_10 = list(map(lambda x: x.split(','), \n",
    "                   open('/workspace/webis20_data/same-stance-detection/within_topic_test_preds_10k.csv', 'r').read().split('\\n')[1:-1]))\n",
    "pred_20 = list(map(lambda x: x.split(','), \n",
    "                   open('/workspace/webis20_data/same-stance-detection/within_topic_test_preds_20k.csv', 'r').read().split('\\n')[1:-1]))\n",
    "pred_30 = list(map(lambda x: x.split(','), \n",
    "                   open('/workspace/webis20_data/same-stance-detection/within_topic_test_preds_30k.csv', 'r').read().split('\\n')[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31475"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(within_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open('/workspace/webis20_data/same-stance-detection/within_topic_test_final.csv', 'w')\n",
    "out_file.write('id,label\\n')\n",
    "for i in range(len(within_test_df)):\n",
    "    if i < 10000:\n",
    "        pred = pred_10[i][1].strip()\n",
    "    if i >= 10000 and i < 20000:\n",
    "        pred = pred_20[i-10000][1].strip()\n",
    "    if i > 20000:\n",
    "        pred = pred_30[i-20000][1].strip()\n",
    "        \n",
    "    out_file.write('{},{} \\n'.format(within_test_df.index[i], pred))\n",
    "    \n",
    "out_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
