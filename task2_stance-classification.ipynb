{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Stance Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/stance-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/stance-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id')\n",
    "cross_test_df =  pd.read_csv(data_cross_path.format('test'),index_col='id')\n",
    "\n",
    "within_traindev_df =  pd.read_csv(data_within_path.format('training'), index_col='id')\n",
    "within_test_df =  pd.read_csv(data_within_path.format('test'), index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if title.find('abortion') > -1 :\n",
    "        row['tag'] = 'abortion'\n",
    "    elif title.find('gay marriage') > -1 :\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "        print(row['debate_title'])\n",
    "    return row\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "within_test_df = within_test_df.apply(add_tag, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_overview(df,  task='stance-classification', class_name = 'stance'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task, '\\n\\n')\n",
    "    print('Total instances: ', total)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        \n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t',is_same_side, ': ', len(side_df), ' instances')\n",
    "            \n",
    "    print()\n",
    "    print()\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "\n",
    "    print('Unique total arguments:', len(df['argument'].unique()))\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    arguments_length_lst = [len(word_tokenize(x)) for x in df['argument'].values]\n",
    "    print('Words:')\n",
    "    print('shortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('longest argument:', max(arguments_length_lst), ' words')\n",
    "    print('aargument average length:', np.mean(arguments_length_lst), ' words')\n",
    "\n",
    "\n",
    "    arguments_sent_length_lst = [len(sent_tokenize(x)) for x in df['argument'].values]\n",
    "    print('Sentences:')\n",
    "    print('shortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('longest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('aargument average length:', np.mean(arguments_sent_length_lst), ' sentences')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview - Cross Topics Train/dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:  stance-classification \n",
      "\n",
      "\n",
      "Total instances:  9426\n",
      "\n",
      "\n",
      "For each topic:\n",
      "abortion :  9426  instances\n",
      "\t\t con :  4615  instances\n",
      "\t\t pro :  4811  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "con :  4615  instances\n",
      "pro :  4811  instances\n",
      "\n",
      "\n",
      "Unique total arguments: 9364\n",
      "\n",
      "\n",
      "Words:\n",
      "shortest argument: 3  words\n",
      "longest argument: 2688  words\n",
      "aargument average length: 416.3171016337789  words\n",
      "Sentences:\n",
      "shortest argument: 1  sentences\n",
      "longest argument: 151  sentences\n",
      "aargument average length: 19.158922130277954  sentences\n"
     ]
    }
   ],
   "source": [
    "get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview - Within Topics Train/dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:  stance-classification \n",
      "\n",
      "\n",
      "Total instances:  9317\n",
      "\n",
      "\n",
      "For each topic:\n",
      "abortion :  6299  instances\n",
      "\t\t con :  3085  instances\n",
      "\t\t pro :  3214  instances\n",
      "gay marriage :  3018  instances\n",
      "\t\t con :  1484  instances\n",
      "\t\t pro :  1534  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "con :  4569  instances\n",
      "pro :  4748  instances\n",
      "\n",
      "\n",
      "Unique total arguments: 9263\n",
      "\n",
      "\n",
      "Words:\n",
      "shortest argument: 3  words\n",
      "longest argument: 2566  words\n",
      "aargument average length: 417.816035204465  words\n",
      "Sentences:\n",
      "shortest argument: 1  sentences\n",
      "longest argument: 145  sentences\n",
      "aargument average length: 19.187828700225396  sentences\n"
     ]
    }
   ],
   "source": [
    "get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model using only train/dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
